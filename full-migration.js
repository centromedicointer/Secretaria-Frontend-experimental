import { createClient } from '@supabase/supabase-js';
import pkg from 'pg';
const { Pool } = pkg;

// Configuraci√≥n de Supabase
const SUPABASE_URL = "https://vdrfdlpwycoghtpqdgvx.supabase.co";
const SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InZkcmZkbHB3eWNvZ2h0cHFkZ3Z4Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzQ3Mjg0NDAsImV4cCI6MjA1MDMwNDQ0MH0.s3g6GSVN-w4zfSao125iE7jjkRgDslWLhOQ-jHlCh9A";

const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);

// Configuraci√≥n de PostgreSQL destino
const pgPool = new Pool({
  connectionString: "postgresql://postgres:1860jBftiIGfh5x8@5.78.154.128:5432/cmit",
  ssl: false,
});

// Tablas a migrar (todas las p√∫blicas)
const PUBLIC_TABLES = [
  'appointment_analytics',
  'appointment_timeline', 
  'appointments',
  'appointments_recordatorios',
  'chat_messages',
  'chats',
  'client_control',
  'customers',
  'documents',
  'evolution_metricas',
  'job_execution_log',
  'kpi_historico',
  'mensajes',
  'n8n_connections',
  'n8n_errores_whatsapp',
  'n8n_errores_whatsapp_historico',
  'n8n_fila_mensagens',
  'n8n_fila_mensagens_personal',
  'n8n_historico_mensagens',
  'n8n_historico_mensagens_personal',
  'n8n_job_config',
  'n8n_logs_notificaciones',
  'n8n_mensajes',
  'n8n_metricas_clasificador',
  'n8n_sesiones_chat',
  'n8n_usuarios_unicos',
  'notificaciones_modificaciones',
  'profiles',
  'reportes_generados',
  'user_dashboard_permissions',
  'user_roles',
  'workflow_control'
];

// Solo tabla users del esquema auth
const AUTH_TABLES = ['users'];

async function fullMigration() {
  console.log('üöÄ Starting FULL database migration from Supabase to PostgreSQL...');
  
  try {
    // 1. Obtener esquema completo de Supabase
    console.log('\nüìã Step 1: Getting complete schema from Supabase...');
    
    // Obtener estructura de tablas p√∫blicas
    console.log('  üìä Getting public table schemas...');
    const tableSchemas = {};
    
    for (const table of PUBLIC_TABLES) {
      console.log(`    - Analyzing ${table}...`);
      const { data, error } = await supabase.rpc('exec', {
        sql: `SELECT column_name, data_type, is_nullable, column_default, character_maximum_length
               FROM information_schema.columns 
               WHERE table_schema = 'public' AND table_name = '${table}'
               ORDER BY ordinal_position`
      });
      
      if (error) {
        console.warn(`    ‚ö†Ô∏è  Could not get schema for ${table}: ${error.message}`);
        continue;
      }
      
      tableSchemas[table] = data;
    }
    
    // Obtener estructura de tabla users de auth
    console.log('  üîê Getting auth.users schema...');
    const { data: usersSchema, error: usersError } = await supabase.rpc('exec', {
      sql: `SELECT column_name, data_type, is_nullable, column_default
             FROM information_schema.columns 
             WHERE table_schema = 'auth' AND table_name = 'users'
             ORDER BY ordinal_position`
    });
    
    if (!usersError) {
      tableSchemas['auth.users'] = usersSchema;
    }
    
    console.log(`  ‚úÖ Analyzed ${Object.keys(tableSchemas).length} tables`);
    
    // 2. Limpiar PostgreSQL y recrear esquema
    console.log('\nüóëÔ∏è  Step 2: Cleaning PostgreSQL database...');
    
    await pgPool.query('DROP SCHEMA IF EXISTS public CASCADE');
    await pgPool.query('CREATE SCHEMA public');
    await pgPool.query('GRANT ALL ON SCHEMA public TO postgres');
    
    console.log('  ‚úÖ PostgreSQL schema cleaned');
    
    // 3. Recrear todas las tablas en PostgreSQL
    console.log('\nüèóÔ∏è  Step 3: Recreating tables in PostgreSQL...');
    
    // Crear tabla users primero
    console.log('  üìã Creating users table...');
    await pgPool.query(`
      CREATE TABLE IF NOT EXISTS users (
        id UUID PRIMARY KEY,
        email VARCHAR(255) UNIQUE,
        encrypted_password VARCHAR(255),
        created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
        updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
      )
    `);
    
    // Crear todas las dem√°s tablas (estructura b√°sica)
    for (const table of PUBLIC_TABLES) {
      console.log(`  üìã Creating table ${table}...`);
      try {
        // Por ahora crear estructura b√°sica, luego podemos refinar
        await pgPool.query(`
          CREATE TABLE IF NOT EXISTS ${table} (
            id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
            updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
          )
        `);
      } catch (error) {
        console.warn(`    ‚ö†Ô∏è  Could not create ${table}: ${error.message}`);
      }
    }
    
    console.log('  ‚úÖ Basic table structure created');
    
    // 4. Migrar datos cr√≠ticos
    console.log('\nüìä Step 4: Migrating critical data...');
    
    // Migrar usuarios
    console.log('  üë• Migrating users...');
    const { data: users, error: usersDataError } = await supabase
      .from('auth.users')
      .select('id, email, encrypted_password, created_at, updated_at')
      .limit(100);
    
    if (!usersDataError && users) {
      for (const user of users) {
        await pgPool.query(`
          INSERT INTO users (id, email, encrypted_password, created_at, updated_at)
          VALUES ($1, $2, $3, $4, $5)
          ON CONFLICT (email) DO UPDATE SET
            encrypted_password = EXCLUDED.encrypted_password,
            updated_at = EXCLUDED.updated_at
        `, [user.id, user.email, user.encrypted_password, user.created_at, user.updated_at]);
      }
      console.log(`    ‚úÖ Migrated ${users.length} users`);
    }
    
    // Migrar tablas cr√≠ticas con datos
    const criticalTables = [
      'user_roles',
      'user_dashboard_permissions', 
      'evolution_metricas',
      'kpi_historico',
      'workflow_control'
    ];
    
    for (const table of criticalTables) {
      console.log(`  üìä Migrating data from ${table}...`);
      try {
        const { data, error } = await supabase
          .from(table)
          .select('*')
          .limit(1000);
        
        if (!error && data && data.length > 0) {
          // Por ahora solo migrar IDs y timestamps b√°sicos
          console.log(`    üìã Found ${data.length} records in ${table}`);
          
          // Aqu√≠ necesitar√≠amos crear la estructura espec√≠fica para cada tabla
          // Por el momento, solo reportamos que encontramos datos
        }
      } catch (error) {
        console.warn(`    ‚ö†Ô∏è  Could not migrate ${table}: ${error.message}`);
      }
    }
    
    console.log('\nüéâ PHASE 1 MIGRATION COMPLETED!');
    console.log('\nüìã Summary:');
    console.log(`  - ‚úÖ Analyzed ${Object.keys(tableSchemas).length} table schemas`);
    console.log(`  - ‚úÖ Recreated basic structure for ${PUBLIC_TABLES.length} tables`);
    console.log(`  - ‚úÖ Migrated users table`);
    console.log('\n‚ö†Ô∏è  NOTE: This is Phase 1. We need to:');
    console.log('  1. Recreate exact column structures for each table');
    console.log('  2. Migrate all data with proper types');
    console.log('  3. Recreate all functions and views');
    console.log('  4. Recreate all indexes and constraints');
    
  } catch (error) {
    console.error('‚ùå Migration failed:', error);
  } finally {
    await pgPool.end();
  }
}

// Ejecutar migraci√≥n
fullMigration().catch(console.error);